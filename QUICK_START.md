# Knowledge Extractor - å¿«é€Ÿå¼€å§‹æŒ‡å—

## é¡¹ç›®æ¦‚è¿°

**Knowledge Extractor** æ˜¯ä¸€ä¸ªæ™ºèƒ½çŸ¥è¯†æç‚¼å’Œç»„ç»‡å¹³å°ï¼Œé›†æˆäº†Manus LLMæœåŠ¡ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åˆ†ææ–‡æ¡£ã€è¯†åˆ«é—®é¢˜å’Œæ–¹æ³•ã€ç”Ÿæˆæ€ç»´å¯¼å›¾ã€‚

### æ ¸å¿ƒåŠŸèƒ½

- ğŸ“„ **æ–‡æ¡£ä¸Šä¼ ** - æ”¯æŒPDFã€TXTã€MDæ ¼å¼
- ğŸ”— **é“¾æ¥å¤„ç†** - æå–ç½‘é¡µå’Œè§†é¢‘å†…å®¹
- ğŸ§  **LLMåˆ†æ** - ä½¿ç”¨Manus LLMè‡ªåŠ¨è¯†åˆ«é—®é¢˜å’Œæ–¹æ³•
- ğŸ“Š **æ€ç»´å¯¼å›¾** - ç”ŸæˆMermaidæ ¼å¼çš„å¯è§†åŒ–æ€ç»´å¯¼å›¾
- ğŸ”„ **æ™ºèƒ½å»é‡** - è¯†åˆ«å’Œå¤„ç†é‡å¤å†…å®¹
- ğŸ’¾ **å¤šæ ¼å¼å¯¼å‡º** - JSONã€Markdownã€CSVã€HTML

## éƒ¨ç½²æ–¹å¼

### æ–¹å¼1ï¼šæœ¬åœ°è¿è¡Œï¼ˆæ¨èç”¨äºå¼€å‘å’Œæµ‹è¯•ï¼‰

#### å‰ç½®è¦æ±‚
- Node.js 18+ 
- npm æˆ– yarn

#### å®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
cd knowledge_extractor

# 2. å®‰è£…ä¾èµ–
npm install

# 3. é…ç½®ç¯å¢ƒå˜é‡
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½® LLM_API_KEY
# LLM_API_KEY=your_manus_api_key_here

# 4. å¯åŠ¨æœåŠ¡
npm start

# æœåŠ¡å°†åœ¨ http://localhost:3000 è¿è¡Œ
```

### æ–¹å¼2ï¼šDockeréƒ¨ç½²ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰

#### å‰ç½®è¦æ±‚
- Docker
- Docker Composeï¼ˆå¯é€‰ï¼‰

#### æ„å»ºå’Œè¿è¡Œ

```bash
# æ„å»ºé•œåƒ
docker build -t knowledge-extractor .

# è¿è¡Œå®¹å™¨
docker run -p 3000:3000 \
  -e LLM_API_KEY=your_manus_api_key_here \
  -v $(pwd)/uploads:/app/uploads \
  -v $(pwd)/data:/app/data \
  knowledge-extractor
```

#### Docker Compose

åˆ›å»º `docker-compose.yml`ï¼š

```yaml
version: '3.8'

services:
  knowledge-extractor:
    build: .
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: production
      LLM_API_KEY: ${LLM_API_KEY}
      UPLOAD_DIR: ./uploads
      DATA_DIR: ./data
    volumes:
      - ./uploads:/app/uploads
      - ./data:/app/data
    restart: unless-stopped
```

è¿è¡Œï¼š
```bash
LLM_API_KEY=your_key docker-compose up -d
```

### æ–¹å¼3ï¼šäº‘å¹³å°éƒ¨ç½²

#### Heroku

```bash
# 1. å®‰è£…Heroku CLI
# 2. ç™»å½•
heroku login

# 3. åˆ›å»ºåº”ç”¨
heroku create knowledge-extractor

# 4. è®¾ç½®ç¯å¢ƒå˜é‡
heroku config:set LLM_API_KEY=your_key

# 5. éƒ¨ç½²
git push heroku main
```

#### Railway / Render / Fly.io

ç±»ä¼¼çš„éƒ¨ç½²æµç¨‹ï¼Œå…·ä½“å‚è€ƒå„å¹³å°æ–‡æ¡£ã€‚

## è·å–LLM APIå¯†é’¥

### ä»Manuså¹³å°è·å–

1. ç™»å½• Manus è´¦æˆ·
2. è¿›å…¥ Settings â†’ Secrets
3. æŸ¥æ‰¾ `BUILT_IN_FORGE_API_KEY` æˆ–åˆ›å»ºæ–°çš„APIå¯†é’¥
4. å¤åˆ¶å¯†é’¥å€¼

### é…ç½®åˆ°Knowledge Extractor

**æ–¹å¼1ï¼šç¯å¢ƒå˜é‡**
```bash
export LLM_API_KEY=your_key
npm start
```

**æ–¹å¼2ï¼š.envæ–‡ä»¶**
```
LLM_API_KEY=your_key
```

**æ–¹å¼3ï¼šDockerç¯å¢ƒå˜é‡**
```bash
docker run -e LLM_API_KEY=your_key ...
```

## ä½¿ç”¨æŒ‡å—

### Webç•Œé¢

æ‰“å¼€æµè§ˆå™¨è®¿é—® `http://localhost:3000`

#### 1. ä¸Šä¼ æ–‡æ¡£

1. ç‚¹å‡»"ä¸Šä¼ æ–‡æ¡£"
2. é€‰æ‹©PDFã€TXTæˆ–MDæ–‡ä»¶
3. ç³»ç»Ÿè‡ªåŠ¨åˆ†æå¹¶è¿”å›ç»“æœ

**æ”¯æŒçš„æ ¼å¼ï¼š**
- PDFï¼ˆä»»ä½•å¤§å°ï¼Œå»ºè®®<50MBï¼‰
- TXTï¼ˆçº¯æ–‡æœ¬ï¼‰
- MDï¼ˆMarkdownï¼‰

#### 2. åˆ†ææ–‡æœ¬

1. ç‚¹å‡»"åˆ†ææ–‡æœ¬"
2. ç²˜è´´è¦åˆ†æçš„å†…å®¹
3. ç‚¹å‡»"åˆ†æ"

#### 3. å¤„ç†é“¾æ¥

1. ç‚¹å‡»"å¤„ç†é“¾æ¥"
2. è¾“å…¥ç½‘é¡µURL
3. ç³»ç»Ÿæå–å†…å®¹å¹¶åˆ†æ

### APIè°ƒç”¨

#### ä¸Šä¼ æ–‡æ¡£åˆ†æ

```bash
curl -X POST http://localhost:3000/api/smart-analysis/upload \
  -F "file=@document.pdf"
```

**å“åº”ç¤ºä¾‹ï¼š**
```json
{
  "success": true,
  "data": {
    "fileName": "document.pdf",
    "contentLength": 5000,
    "analysis": {
      "problem": "å¦‚ä½•å¤‡è€ƒKETå†™ä½œ",
      "methods": [
        "æŒæ¡åŸºæœ¬å†™ä½œç»“æ„",
        "ç§¯ç´¯å¸¸ç”¨è¡¨è¾¾",
        "å®šæœŸç»ƒä¹ å’Œåé¦ˆ"
      ],
      "keywords": ["KET", "å†™ä½œ", "å¤‡è€ƒ"],
      "summary": "ä»‹ç»äº†KETå†™ä½œå¤‡è€ƒçš„ç³»ç»Ÿæ–¹æ³•...",
      "mindmap": "mindmap\n  root((å¦‚ä½•å¤‡è€ƒKETå†™ä½œ))\n    æ–¹æ³•\n      æ–¹æ³•1: æŒæ¡åŸºæœ¬å†™ä½œç»“æ„\n      ..."
    }
  }
}
```

#### åˆ†ææ–‡æœ¬

```bash
curl -X POST http://localhost:3000/api/smart-analysis/text \
  -H "Content-Type: application/json" \
  -d '{
    "content": "è¦åˆ†æçš„æ–‡æœ¬å†…å®¹",
    "contentType": "text"
  }'
```

#### å¤„ç†é“¾æ¥

```bash
curl -X POST http://localhost:3000/api/smart-analysis/link \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com"
  }'
```

#### è·å–ç³»ç»Ÿç»Ÿè®¡

```bash
curl http://localhost:3000/api/stats
```

**å“åº”ï¼š**
```json
{
  "success": true,
  "stats": {
    "knowledgePoints": 10,
    "documents": 5,
    "links": 3,
    "documentsProcessing": 0,
    "linksProcessing": 0
  }
}
```

## è¾“å‡ºæ ¼å¼

### JSONæ ¼å¼

æ¯ä¸ªåˆ†æç»“æœéƒ½åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{
  "problem": "æ ¸å¿ƒé—®é¢˜ï¼ˆç®€æ´å‡†ç¡®ï¼‰",
  "methods": [
    "å…·ä½“æ–¹æ³•1",
    "å…·ä½“æ–¹æ³•2",
    "å…·ä½“æ–¹æ³•3"
  ],
  "keywords": [
    "å…³é”®è¯1",
    "å…³é”®è¯2",
    "å…³é”®è¯3"
  ],
  "summary": "å†…å®¹æ€»ç»“ï¼ˆç²¾ç‚¼å‡†ç¡®ï¼‰",
  "mindmap": "Mermaidæ€ç»´å¯¼å›¾ä»£ç ",
  "contentType": "document|text|link",
  "analyzedAt": "2024-01-06T10:30:00Z"
}
```

### Markdownæ ¼å¼

å¯ä»¥å¯¼å‡ºä¸ºMarkdownä¾›äººç±»é˜…è¯»ï¼š

```markdown
# é—®é¢˜ï¼šå¦‚ä½•å¤‡è€ƒKETå†™ä½œ

## è§£å†³æ–¹æ³•

1. æŒæ¡åŸºæœ¬å†™ä½œç»“æ„
2. ç§¯ç´¯å¸¸ç”¨è¡¨è¾¾
3. å®šæœŸç»ƒä¹ å’Œåé¦ˆ

## å…³é”®è¯

- KET
- å†™ä½œ
- å¤‡è€ƒ

## æ€ç»´å¯¼å›¾

[Mermaidå›¾è¡¨å¯è§†åŒ–]
```

## æµ‹è¯•

### æœ¬åœ°æµ‹è¯•

```bash
# 1. å¯åŠ¨æœåŠ¡
npm start

# 2. åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•API
curl -X POST http://localhost:3000/api/smart-analysis/text \
  -H "Content-Type: application/json" \
  -d '{
    "content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬",
    "contentType": "text"
  }'
```

### ä½¿ç”¨æµ‹è¯•PDF

é¡¹ç›®åŒ…å«ä¸€ä¸ªæµ‹è¯•PDFæ–‡ä»¶ï¼ˆ15ç« .pdfï¼‰ï¼Œæ‚¨å¯ä»¥ç”¨å®ƒæ¥æµ‹è¯•ï¼š

```bash
curl -X POST http://localhost:3000/api/smart-analysis/upload \
  -F "file=@/path/to/15ç« .pdf"
```

## æ•…éšœæ’é™¤

### é—®é¢˜ï¼šLLM APIé”™è¯¯

**é”™è¯¯ä¿¡æ¯ï¼š** `LLM API Key not configured`

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®ä¿ `.env` æ–‡ä»¶ä¸­é…ç½®äº† `LLM_API_KEY`
2. ç¡®ä¿å¯†é’¥æœ‰æ•ˆ
3. æ£€æŸ¥ç½‘ç»œè¿æ¥

### é—®é¢˜ï¼šæ–‡ä»¶ä¸Šä¼ å¤±è´¥

**é”™è¯¯ä¿¡æ¯ï¼š** `File too large` æˆ– `File type not allowed`

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé»˜è®¤é™åˆ¶50MBï¼‰
2. ç¡®ä¿æ–‡ä»¶æ ¼å¼æ˜¯PDFã€TXTæˆ–MD
3. ä¿®æ”¹ `.env` ä¸­çš„ `MAX_FILE_SIZE` æˆ– `ALLOWED_FILE_TYPES`

### é—®é¢˜ï¼šPDFæå–å¤±è´¥

**é”™è¯¯ä¿¡æ¯ï¼š** `Failed to extract PDF content`

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®ä¿PDFæ–‡ä»¶æœ‰æ•ˆ
2. ç¡®ä¿PDFä¸å—å¯†ç ä¿æŠ¤
3. å°è¯•ç”¨å…¶ä»–PDFæŸ¥çœ‹å™¨æ‰“å¼€æ–‡ä»¶

## æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜

å®ç°ç¼“å­˜é¿å…é‡å¤åˆ†æç›¸åŒå†…å®¹ï¼š

```javascript
// åœ¨ llmAnalyzer.js ä¸­æ·»åŠ ç¼“å­˜
const cache = new Map();
const cacheKey = hash(content);
if (cache.has(cacheKey)) {
  return cache.get(cacheKey);
}
```

### 2. å¼‚æ­¥å¤„ç†

å¤§æ–‡ä»¶ä½¿ç”¨å¼‚æ­¥å¤„ç†ï¼š

```javascript
// ä½¿ç”¨é˜Ÿåˆ—å¤„ç†å¤§æ–‡ä»¶
const queue = [];
const processQueue = async () => {
  while (queue.length > 0) {
    const item = queue.shift();
    await processItem(item);
  }
};
```

### 3. åˆ†æ®µå¤„ç†

è¶…å¤§æ–‡æ¡£åˆ†æ®µå¤„ç†ï¼š

```javascript
// å°†å¤§æ–‡æ¡£åˆ†æˆå°æ®µ
const chunks = splitDocument(content, chunkSize);
const results = await Promise.all(
  chunks.map(chunk => analyzeContent(chunk))
);
```

## åç»­åŠŸèƒ½

### ç¬¬äºŒé˜¶æ®µ

- [ ] ç”¨æˆ·è®¤è¯å’Œæˆæƒ
- [ ] çŸ¥è¯†åº“ç®¡ç†ç•Œé¢
- [ ] é«˜çº§æœç´¢åŠŸèƒ½
- [ ] çŸ¥è¯†ç‚¹å…³è”ç®¡ç†
- [ ] æ‰¹é‡å¯¼å…¥/å¯¼å‡º
- [ ] æ•°æ®æŒä¹…åŒ–å­˜å‚¨

### ç¬¬ä¸‰é˜¶æ®µ

- [ ] ä¸è‹±è¯­å­¦ä¹ APPé›†æˆ
- [ ] æ¨èå¼•æ“
- [ ] å­¦ä¹ è®¡åˆ’ç”Ÿæˆ
- [ ] è¿›åº¦è·Ÿè¸ª
- [ ] å­¦ç”Ÿç®¡ç†

## æ”¯æŒå’Œåé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿã€‚

---

**æœ€åæ›´æ–°**ï¼š2024å¹´1æœˆ6æ—¥
**ç‰ˆæœ¬**ï¼š1.0.0
